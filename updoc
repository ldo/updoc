#!/usr/bin/python3
#+
# Tool to maintain versions of a set of one or more related files
# in an SQLite database.
#
# Copyright 2021 by Lawrence D'Oliveiro <ldo@geek-central.gen.nz>.
# Licensed under CC-BY-SA <http://creativecommons.org/licenses/by-sa/4.0/>.
#-

import sys
import os
import math
import enum
import stat
from hashlib import \
    sha256
import re
import time
import subprocess
import tempfile
import fnmatch
import shutil
import getopt
import apsw as sqlite

#+
# Useful stuff
#-

def format_timestamp(timestamp) :
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(round(timestamp)))
#end format_timestamp

#+
# Database stuff
#-

class DB_OPEN(enum.IntEnum) :
    "database opening modes."
    READONLY = 0 # existing database, only for reading
    READWRITE = 1 # existing database, for reading and writing
    READWRITECREATE = 2 # create database if it doesn’t exist, open for reading and writing
#end DB_OPEN

def db_iter(conn, cmd, mapfn = lambda x : x) :
    "executes cmd on a new cursor from connection conn and yields the results in turn."
    for item in conn.cursor().execute(cmd) :
        yield mapfn(item)
    #end for
#end db_iter

single_field = lambda x : x[0]

def db_func(conn, funcname) :
    "executes the named function in a select statement and returns its value."
    result, = list(db_iter
      (
        conn,
        "select %s()" % funcname,
        mapfn = single_field
      ))
    return result
#end db_func

def db_tables(conn) :
    "returns the set of table names in the given SQLite database."
    return \
        set(db_iter
          (
            conn,
            "select tbl_name from sqlite_schema where type = \"table\"",
            mapfn = single_field
          ))
#end db_tables

class DIRKIND(enum.Enum) :
    "how to interpret file/dir specs in filter rules."
    ROOT = 0 # interpret as spec relative to root dir
    HASDIR = 1 # specs consist of parent dir followed by one or more child specs
    EVERYWHERE = 2 # interpret as spec relative to root dir and all subdirs
    ISDIR = 3 # spec is itself a dir of which all contained files are to be included
#end DIRKIND

class RULE_ACTION(enum.Enum) :
    "kinds of filter rules."
    INCLUDE = ("include", True, DIRKIND.ROOT, 0, None)
    EXCLUDE = ("exclude", False, DIRKIND.ROOT, 0, None)
    RECURSIVE_INCLUDE = \
        ("recursive-include", True, DIRKIND.HASDIR, 2,
            "required parent directory and at least one child filespec")
    RECURSIVE_EXCLUDE = \
        ("recursive-exclude", False, DIRKIND.HASDIR, 2,
            "required parent directory and at least one child filespec")
    GLOBAL_INCLUDE = ("global-include", True, DIRKIND.EVERYWHERE, 0, None)
    GLOBAL_EXCLUDE = ("global-exclude", False, DIRKIND.EVERYWHERE, 0, None)
    GRAFT = ("graft", True, DIRKIND.ISDIR, 0, None)
    PRUNE = ("prune", False, DIRKIND.ISDIR, 0, None)

    @property
    def keyword(self) :
        return self.value[0]
    #end keyword

    @property
    def include_matching(self) :
        "True to include matching items, False to exclude them."
        return self.value[1]
    #end include_matching

    @property
    def dirkind(self) :
        return self.value[2]
    #end dirkind

    @property
    def min_args(self) :
        "minimum number of pathspec args to this action."
        return self.value[3]
    #end min_args

    @property
    def msg_required_args(self) :
        "message to show for incorrect args."
        return self.value[4]
    #end msg_required_args

#end RULE_ACTION
RULE_ACTION.from_keyword = dict((i.keyword, i) for i in RULE_ACTION)

snapshot_tables = \
    {
        "snapshots" :
            [
                "id integer primary key autoincrement",
                "comment varchar not null",
                "timestamp double not null",
            ],
        "files" :
            [
                "snapshot_id integer not null", # = snapshots.id
                "path varchar not null",
                "timestamp double not null",
                "sha256hash varchar not null", # = file_blobs.sha256hash
                "primary key (snapshot_id, path)",
            ],
        "file_blobs" : # contents of files separated out to allow deduping
            [
                "contents blob not null",
                "sha256hash varchar primary key not null", # hex hash of contents
            ],
    }
snapshot_filter_tables = \
    {
        "filter_rules" :
            [
                "ordering integer primary key not null", # for ordering of rules
                "action varchar not null",
            ],
        "filter_items" :
            [
                "rule_ordering integer not null", # = filter_rules.filter_item
                "item_ordering integer not null", # for ordering of items within rule
                "pathspec varchar not null",
                "primary key(rule_ordering, item_ordering)",
            ],
    }

def open_db(dbname, mode, using_filters = True) :
    "opens the specified database file and returns a new connection. mode is DB_OPEN value."
    if mode == DB_OPEN.READWRITECREATE :
        fd = os.open(dbname, flags = os.O_RDWR | os.O_CREAT | os.O_EXCL)
          # try to guarantee not overwriting existing file when creating database
    else :
        fd = None
    #end if
    result = \
        sqlite.Connection \
          (
            dbname,
            flags =
                (sqlite.SQLITE_OPEN_READONLY, sqlite.SQLITE_OPEN_READWRITE)
                    [mode >= DB_OPEN.READWRITE]
          )
    if fd != None :
        os.close(fd)
    #end if
    create_tables = dict(snapshot_tables)
    to_create = set(create_tables.keys())
    existing_tables = set(db_tables(result)) & to_create
    if existing_tables != to_create and (len(existing_tables) != 0 or mode < DB_OPEN.READWRITECREATE) :
        raise RuntimeError("File “%s” does not look like a snapshots database" % dbname)
    #end if
    if len(existing_tables) == 0 :
        sys.stderr.write("Initializing new database\n") # debug
        if using_filters :
            create_tables.update(snapshot_filter_tables)
        #end if
        cu = result.cursor()
        for table_name, fields in create_tables.items() :
            cmd = \
                (
                        "create table %(table)s\n"
                        "  (\n"
                        "%(fields)s\n"
                        "  )"
                    %
                        {
                            "table" : table_name,
                            "fields" : ",\n".join("    " + field for field in fields),
                        }
                )
            sys.stderr.write(cmd + "\n") # debug
            cu.execute(cmd)
        #end for
        cu.close()
    #end if
    return \
        result
#end open_db_common

def has_filtering(db) :
    "does this database use filtering rules."
    filter_tables = set(snapshot_filter_tables.keys())
    return set(db_tables(db)) & filter_tables == filter_tables
#end has_filtering

def parse_wildcard(parent, child) :
    # returns a compiled re.Pattern object that will match filenames
    # according to a given parent directory and child item pattern
    # that can contain shell-style wildcards.

    def parse_wildcard_path(s, default) :
        # returns an re.Pattern string that matches a given string that
        # can contain shell-style wildcards.
        if s != None :
            if s.startswith("/") :
                raise ValueError("relative pathspecs only")
            #end if
            t = ""
            i = 0
            cur_set = None
            while True :
                if i == len(s) :
                    if cur_set != None :
                        raise ValueError("incomplete “[...]” sequence")
                    #end if
                    break
                #end if
                c = s[i]
                i += 1
                if c == "\\" :
                    if i == len(s) :
                        raise ValueError("incomplete “\\” sequence")
                    #end if
                    c = s[i]
                    i += 1
                    if c == "n" :
                        c = "\n"
                    elif c == "t" :
                        c = "\t"
                    #end if
                    c = re.escape(c)
                elif cur_set == None and c == "*" :
                    if i < len(s) and s[i] == "*" :
                        i += 1
                        c = ".*" # can match “/”
                    else :
                        c = "[^\\/]*"
                    #end if
                elif cur_set == None and c == "?" :
                    c = "[^\\/]"
                elif cur_set == None and c == "[" :
                    cur_set = ""
                    c = None
                elif cur_set != None and len(cur_set) == 0 and c == "^" :
                    pass # include c as-is
                elif cur_set != None and c == "]" :
                    c = "[" + cur_set + "]"
                    cur_set = None
                else :
                    c = re.escape(c)
                #end if
                if c != None :
                    if cur_set != None :
                        cur_set += c
                    else :
                        t += c
                    #end if
                #end if
            #end while
        else :
            t = default
        #end if
        return \
            t
    #end parse_wildcard_path

#begin parse_wildcard
    if parent != None :
        while parent.endswith("/") :
            parent = parent[:-1]
        #end while
    #end if
    parent_pat = parse_wildcard_path(parent, "")
    child_pat = parse_wildcard_path(child, ".*")
    if parent_pat != "" :
        pat = parent_pat + "\\/(?:.+\\/)*" + child_pat
    else :
        pat = child_pat
    #end if
    if parent == None :
        # match filename anywhere in hierarchy
        pat = "(?:.+\\/)*" + pat
    #end if
    return \
        re.compile("^" + pat + "$", re.DOTALL)
#end parse_wildcard

def parse_manifest(contents) :
    "parses a string which has the format of the contents of a MANIFEST.in" \
    " file. Returns the tokenized filter rule text without further interpretation."

    def tokenize_line(s) :
        if "\t" in s :
            raise SyntaxError("no tabs allowed")
            # or I could fix parser to handle as part of whitespace
        #end if
        result = []
        cur_token = None
        while len(s) != 0 :
            pos1 = s.find("\\")
            pos2 = s.find(" ")
            if pos1 < 0 :
                pos1 = len(s)
            #end if
            if pos2 < 0 :
                pos2 = len(s)
            #end if
            if cur_token == None and pos2 != 0 :
                cur_token = ""
            #end if
            if pos1 < pos2 :
                if pos1 + 1 == len(s) :
                    raise ValueError("incomplete “\\” sequence")
                #end if
                cur_token += s[:pos1 + 2]
                s = s[pos1 + 2:]
            else : # pos2 < pos1
                if cur_token != None :
                    cur_token += s[:pos2]
                    result.append(cur_token)
                    cur_token = None
                #end if
                s = s[pos2 + 1:]
            #end if
        #end while
        return \
            result
    #end tokenize_line

#begin parse_manifest
    result = []
    had_comments = False
    for line in contents.split("\n") :
        line = line.lstrip()
        if line.startswith("#") :
            had_comments = True
        else :
            items = tokenize_line(line)
            if len(items) != 0 :
                keyword = items[0]
                action = RULE_ACTION.from_keyword.get(keyword)
                if action == None :
                    raise ValueError("unrecognized rule keyword “%s”" % keyword)
                #end if
                if any(item.startswith("/") for item in items) :
                    raise ValueError("relative pathspecs only: “%s”" % line)
                #end if
                if any(".." in item.split("/") for item in items) :
                    raise ValueError("no uplevel references in pathspecs: “%s”" % line)
                #end if
                if len(items) < action.min_args + 1 :
                    raise ValueError("%s for %s" % (action.msg_required_args, keyword))
                #end if
                result.append(items)
            #end if
        #end if
    #end for
    return \
        result, had_comments
#end parse_manifest

def load_filters(db) :
    "generator which loads the filter specs from the database."
    rules_iter = db_iter \
      (
        db,
        "select filter_rules.ordering, filter_items.item_ordering, filter_rules.action,"
        " filter_items.pathspec from filter_rules left join filter_items on"
        " filter_rules.ordering = filter_items.rule_ordering order by"
        " filter_rules.ordering, filter_items.item_ordering"
      )
    last_rule_index = None
    last_rule_action = None
    rule_items = None
    while True :
        item = next(rules_iter, None)
        if item != None :
            rule_index, item_index, rule_action, item_pathspec = item
        else :
            rule_index = None
        #end if
        if rule_index == None or rule_index != last_rule_index :
            if last_rule_index != None :
                yield (last_rule_action, rule_items)
                last_rule_index = None
            #end if
            if rule_index == None :
                break
            last_rule_index = rule_index
            last_rule_action = rule_action
            rule_items = []
        #end if
        if item_pathspec != None :
            rule_items.append(item_pathspec)
        #end if
    #end while
#end load_filters

def parse_filters(db) :
    "generator which loads and parses the filter specs from the database," \
    " yielding («include_matching», «match_pattern») pairs in order."
    for action, items in load_filters(db) :
        action = RULE_ACTION.from_keyword[action]
        to_parse = \
            {
                DIRKIND.ROOT : lambda item : ("", item),
                DIRKIND.HASDIR : lambda parent : lambda item : (parent, item),
                DIRKIND.EVERYWHERE : lambda item : (None, item),
                DIRKIND.ISDIR : lambda item : (item, None),
            }[action.dirkind]
        if action.min_args > 1 :
            to_parse = to_parse(items.pop(0))
        #end if
        for item in items :
            yield (action.include_matching, parse_wildcard(*to_parse(item)))
        #end for
    #end for
#end parse_filters

def set_filters(db, filters) :
    "sets new filters on the specified snapshot database."
    cu = db.cursor()
    cu.execute("begin transaction")
    for table in ("filter_items", "filter_rules") :
        cu.execute("delete from %s" % table)
    #end for
    rule_index = 0
    for items in filters :
        rule_index += 1
        action = items.pop(0)
        cu.execute \
          (
                "insert into filter_rules(ordering, action) values(%d, %s)"
            %
                (rule_index, sqlite.format_sql_value(action))
          )
        item_index = 0
        for item in items :
            item_index += 1
            cu.execute \
              (
                    "insert into filter_items(rule_ordering, item_ordering, pathspec)"
                    " values (%d, %d, %s)"
                %
                    (rule_index, item_index, sqlite.format_sql_value(item))
              )
        #end for
    #end for
    cu.execute("end transaction")
    cu.close()
#end set_filters

def filter_says_include(pathspec, rules) :
    i = len(rules)
    while True :
        if i == 0 :
            includeit = False
            break
        #end if
        i -= 1
        do_include, matching = rules[i]
        if matching.search(pathspec) != None :
            includeit = do_include
            break
        #end if
    #end while
    return includeit
#end filter_says_include

class EXIST_ACTION(enum.Enum) :
    "how to handle creation of a file if one already exists with that name."
    ERROR = ("error",)
    SKIP = ("skip",)
    REPLACE = ("replace",)
    REPLACE_ALL = ("replace-all",)

    @property
    def keyword(self) :
        return self.value[0]
    #end keyword

#end EXIST_ACTION
EXIST_ACTION.from_keyword = dict((i.keyword, i) for i in EXIST_ACTION)

def parse_exist_action(k, allow_replace_all) :
    if k != None :
        action = EXIST_ACTION.from_keyword.get(k)
        if action == EXIST_ACTION.REPLACE_ALL and not allow_replace_all :
            action = None
        #end if
        if action == None :
            raise getopt.GetoptError \
              (
                    "unrecognized --existing action %s -- must be one of %s"
                %
                    (
                        k,
                        ", ".join
                          (
                            sorted
                              (
                                k for k in EXIST_ACTION.from_keyword
                                if allow_replace_all or k != EXIST_ACTION.REPLACE_ALL.keyword
                              )
                          )
                    )
              )
        #end if
    else :
        action = EXIST_ACTION.ERROR
    #end if
    return action
#end parse_exist_action

def get_filespecs_to_save(basedir, filespecs) :
    if len(filespecs) == 0 :
        raise getopt.GetoptError \
          (
            "this database does not use filter rules -- explicit filespecs are required"
          )
    #end if
    to_save = list(os.path.abspath(f) for f in filespecs)
    invalid = list(f for f in to_save if not f.startswith(basedir + "/"))
    if len(invalid) != 0 :
        raise getopt.GetoptError \
          (
            "filespecs to save outside basedir %s: %s\n" % (basedir, ", ".join(invalid))
          )
    #end if
    info = dict((f, os.lstat(f)) for f in to_save)
    invalid = list(f for f in to_save if not stat.S_ISREG(info[f].st_mode))
    if len(invalid) != 0 :
        raise getopt.GetoptError("not regular files: %s\n" % ", ".join(invalid))
    #end if
    to_save = list \
      (
        {"path" : f[len(basedir) + 1:], "timestamp" : info[f].st_mtime}
        for f in to_save
      )
    return to_save
#end get_filespecs_to_save

def save_files(cu, snapid, basedir, to_save, exist_action, doit) :
    for item in to_save :
        sys.stdout.write("%ssave %s\n" % (("would ", "")[doit], item["path"]))
        if doit :
            contents = open(os.path.join(basedir, item["path"]), "rb").read()
            contents_hash = sha256(contents).hexdigest()
            cu.execute \
              (
                    "insert or ignore into file_blobs(contents, sha256hash) values(%s, %s)"
                %
                    (
                        sqlite.format_sql_value(contents),
                        sqlite.format_sql_value(contents_hash),
                    )
              )
            cu.execute \
              (
                    "insert or %(exist_action)s into files(snapshot_id, path, timestamp, sha256hash)"
                    " values(%(snapid)d, %(path)s, %(timestamp)s, %(hash)s)"
                %
                    {
                        "exist_action" :
                            {
                                EXIST_ACTION.ERROR : "abort",
                                EXIST_ACTION.SKIP : "ignore",
                                EXIST_ACTION.REPLACE : "replace",
                            }[exist_action],
                        "snapid" : snapid,
                        "path" : sqlite.format_sql_value(item["path"]),
                        "timestamp" : str(item["timestamp"]),
                        "hash" : sqlite.format_sql_value(contents_hash),
                    }
              )
        #end if
    #end for
#end save_files

def gc_blobs(db, cu = None) :
    "deletes unreferenced file_blob entries."
    if cu == None :
        cu = db.cursor()
    #end if
    cu.execute("delete from file_blobs where sha256hash not in (select sha256hash from files)")
    blobs_deleted = db_func(db, "changes")
    if blobs_deleted != 0 :
        cu.execute("vacuum")
    #end if
    return blobs_deleted
#end gc_blobs

def get_editor(opts) :
    "returns the user’s specification of text editor to use. Raises error" \
    " if none can be found."
    editor = opts.get("editor")
    if editor == None :
        editor = os.environ.get("EDITOR")
    #end if
    if editor == None :
        raise getopt.GetoptError("no --editor or $EDITOR specified")
    #end if
    return editor
#end get_editor

class EditText :
    "common code for managing a temporary file used to let the user" \
    " interactively edit some text data. “category” is used to give" \
    " a distinctive name to the temporary file."

    def __init__(self, opts, category) :
        self.editor = get_editor(opts)
        self.tempfd, self.tempfilename = \
            tempfile.mkstemp(prefix = "updoc-", suffix = "-" + category)
    #end __init__

    def edit(self, text) :
        "brings up the editor to let the user edit the given text." \
        " Returns process exist status and the new text or None."
        os.ftruncate(self.tempfd, 0)
        os.write(self.tempfd, text.encode())
        status = subprocess.call \
          (
            args = (self.editor, self.tempfilename),
          )
        if status == 0 :
            new_text_len = os.lseek(self.tempfd, 0, os.SEEK_END)
            os.lseek(self.tempfd, 0, os.SEEK_SET)
            new_text = os.read(self.tempfd, new_text_len).decode()
        else :
            new_text = None
        #end if
        return status, new_text
    #end edit

    def cleanup(self) :
        os.unlink(self.tempfilename)
        os.close(self.tempfd)
        self.tempfilename = self.tempfd = None
    #end cleanup

#end EditText

#+
# Definitions of valid commands.
#
# Each command function is passed two arguments: the first is
# the list of positional arguments, and the second is the
# dictionary of option keywords and corresponding values
# that were specified.
#-

def cmd_help(args, opts) :
    "shows the user the help description for a command, or for the help" \
    " command itself if no valid command is given."
    command_candidates = None
    command_match = None
    if len(args) == 1 :
        cmd = args[0]
        if cmd not in recognized_commands :
            command_match = cmd
            cmd = None
            command_candidates = list \
              (
                c for c in recognized_commands.keys()
                if fnmatch.fnmatch(c, command_match)
              )
        #end if
    else :
        cmd = "help"
        command_candidates = recognized_commands.keys()
    #end if
    if cmd != None :
        sys.stderr.write \
          (
                "Usage:\n\n\t%s %s %s\n\n%s.\n"
            %
                (
                    sys.argv[0],
                    cmd,
                    recognized_commands[cmd]["help_usage"],
                    recognized_commands[cmd]["help_descr"],
                )
          )
    #end if
    if command_candidates != None :
        if len(command_candidates) != 0 :
            sys.stderr.write \
              (
                    "\nValid commands%(matching)s are: %(commands)s.\n"
                %
                    {
                        "matching" :
                            ["", " matching \"%s\"" % command_match][command_match != None],
                        "commands" : ", ".join(sorted(command_candidates)),
                    }
              )
        else :
            sys.stderr.write("No commands matching \"%s\".\n" % command_match)
        #end if
    #end if
#end cmd_help

def cmd_init(args, opts) :
    dbname, = args
    using_filters = "nofilters" not in opts
    db = open_db(dbname, DB_OPEN.READWRITECREATE, using_filters = using_filters)
    db.close()
#end cmd_init

def cmd_setfilters(args, opts) :
    dbname, filter_filename = args
    filters = parse_manifest(open(filter_filename, "rt").read())[0]
    db = open_db(dbname, DB_OPEN.READWRITE)
    if not has_filtering(db) :
        raise getopt.GetoptError("database %s does not use filters" % dbname)
    #end if
    set_filters(db, filters)
    db.close()
#end cmd_setfilters

def cmd_showfilters(args, opts) :
    dbname, = args
    db = open_db(dbname, DB_OPEN.READONLY)
    if not has_filtering(db) :
        raise getopt.GetoptError("database %s does not use filters" % dbname)
    #end if
    first = True
    for action, items in load_filters(db) :
        first = False
        sys.stdout.write(" ".join([action] + items) + "\n")
    #end for
    if first :
        sys.stdout.write("# No filter rules found.\n")
    #end if
    db.close()
#end cmd_showfilters

def cmd_editfilters(args, opts) :
    dbname, = args
    db = open_db(dbname, DB_OPEN.READWRITE)
    if not has_filtering(db) :
        raise getopt.GetoptError("database %s does not use filters" % dbname)
    #end if
    editing = EditText(opts, "filters")
    status, new_rules = editing.edit \
      (
        "".join
          (
            " ".join([action] + items) + "\n"
            for action, items in load_filters(db)
          )
      )
    if status != 0 :
        sys.stdout.write \
          (
            "editor %s terminated with status %d -- edit aborted\n" % (editing.editor, status)
          )
    else :
        filters, had_comments = parse_manifest(new_rules)
        if len(filters) != 0 or had_comments :
            set_filters(db, filters)
            if len(filters) != 0 :
                sys.stdout.write("%d new filters installed\n" % len(filters))
            else :
                sys.stdout.write("all existing filters deleted\n")
            #end if
        else :
            sys.stdout.write("edit aborted\n")
        #end if
    #end if
    db.close()
    editing.cleanup()
#end cmd_editfilters

def cmd_list(args, opts) :
    dbname, = args
    long_listing = "long" in opts
    db = open_db(dbname, DB_OPEN.READONLY)
    first = True
    if long_listing :
        last_snap_id = None
        iter_snaps = db_iter \
          (
            db,
            "select id, comment, snapshots.timestamp, files.path, files.timestamp,"
            " length(file_blobs.contents) from"
            " snapshots left join files on snapshots.id = files.snapshot_id"
            " left join file_blobs on files.sha256hash = file_blobs.sha256hash"
            " order by snapshots.timestamp, snapshots.id, files.path"
          )
        while True :
            snap = next(iter_snaps, None)
            if snap != None :
                snap_id, comment, snap_timestamp, filepath, file_timestamp, file_size = snap
                assert filepath == None or file_size != None
            else :
                snap_id = None
            #end if
            if snap_id == None or snap_id != last_snap_id :
                if last_snap_id != None :
                    sys.stdout.write("Total of %d files, %d bytes\n" % (nr_files, total_size))
                #end if
                if snap_id == None :
                    break
                if not first :
                    sys.stdout.write("\n")
                #end if
                first = False
                sys.stdout.write("* snap ID %d at %s\n" % (snap_id, format_timestamp(snap_timestamp)))
                if len(comment) != 0 :
                    sys.stdout.write("  ")
                    sys.stdout.write(comment)
                    sys.stdout.write("\n")
                #end if
                last_snap_id = snap_id
                nr_files = total_size = 0
            #end if
            if filepath == None :
                sys.stdout.write("  (No files)\n")
            else :
                sys.stdout.write \
                  (
                        "  %10d %19s %s\n"
                    %
                        (
                            file_size,
                            format_timestamp(file_timestamp),
                            filepath,
                        )
                  )
                total_size += file_size
                nr_files += 1
            #end if
        #end while
    else :
        for id, comment, timestamp, nr_files in db_iter \
          (
            db,
            "select id, comment, snapshots.timestamp, count(*) from"
            " snapshots left join files on snapshots.id = files.snapshot_id"
            " group by snapshot_id order by snapshots.timestamp"
          ) \
        :
            if first :
                sys.stdout.write \
                  (
                    "id          when          files       comment\n"
                    "---  -------------------  -----  ----------------\n"
                  )
                first = False
            #end if
            sys.stdout.write \
              (
                    "%0.3d  %s  %5d  %s\n"
                %
                    (
                        id,
                        format_timestamp(timestamp),
                        nr_files,
                        comment,
                    )
              )
        #end for
    #end if
    if first :
        sys.stdout.write("No saved snapshots found.\n")
    #end if
    db.close()
#end cmd_list

def cmd_save(args, opts) :
    dbname, basedir = args[0:2]
    filespecs = args[2:]
    basedir = os.path.abspath(basedir)
    if not stat.S_ISDIR(os.lstat(basedir).st_mode) :
        raise ValueError("not a directory: “%s”" % basedir)
    #end if
    message = opts.get("message", "")
    doit = "dry-run" not in opts
    db = open_db(dbname, DB_OPEN.READWRITE)
    if has_filtering(db) :
        if len(filespecs) != 0 :
            raise getopt.GetoptError("filtering rules in effect, no explicit filespecs allowed")
        #end if
        rules = list(parse_filters(db))
        if len(rules) == 0 :
            raise ValueError("no rules specifying what to save")
        #end if
        def get_files(dirname, basename) :
            result = []
            for item in os.listdir(dirname) :
                childitem = os.path.join(dirname, item)
                childname = os.path.join(basename, item)
                info = os.lstat(childitem)
                if stat.S_ISREG(info.st_mode) :
                    if filter_says_include(childname, rules) :
                        result.append({"path" : childname, "timestamp" : info.st_mtime})
                    #end if
                elif stat.S_ISDIR(info.st_mode) :
                    result.extend(get_files(childitem, childname))
                #end if
            #end for
            return result
        #end get_files
        to_save = get_files(basedir, "")
    else :
        to_save = get_filespecs_to_save(basedir, filespecs)
    #end if
    sys.stdout.write("files to save: %s\n" % repr(to_save)) # debug
    if len(to_save) == 0 :
        raise ValueError("no matching files to save")
    #end if
    cu = db.cursor()
    cu.execute("begin transaction")
    snaptime = time.time()
    if doit :
        cu.execute \
          (
                "insert into snapshots(comment, timestamp) values(%s, %s)"
            %
                (sqlite.format_sql_value(message), str(snaptime))
          )
        snapid = db_func(db, "last_insert_rowid")
    else :
        snapid = None
    #end if
    save_files(cu, snapid, basedir, to_save, EXIST_ACTION.ERROR, doit)
    cu.execute("end transaction")
    cu.close()
    db.close()
    if doit :
        sys.stdout.write \
          (
            "%d files saved in snapshot ID %d\n" % (len(to_save), snapid)
          )
    else :
        sys.stdout.write \
          (
            "%d files would have been saved\n" % len(to_save)
          )
    #end if
#end cmd_save

def cmd_save_more(args, opts) :
    dbname, snapid, basedir = args[0:3]
    snapid = int(snapid)
    basedir = os.path.abspath(basedir)
    filespecs = args[3:]
    exist_action = parse_exist_action(opts.get("existing"), False)
    doit = "dry-run" not in opts
    db = open_db(dbname, DB_OPEN.READWRITE)
    if has_filtering(db) :
        raise getopt.GetoptError("filtering rules in effect, no explicit filespecs allowed")
    #end if
    if next(db_iter(db, "select id from snapshots where id = %d" % snapid), None) == None :
        raise ValueError("no such snapshot with ID %d" % snapid)
    #end if
    to_save = get_filespecs_to_save(basedir, filespecs)
    cu = db.cursor()
    cu.execute("begin transaction")
    save_files(cu, snapid, basedir, to_save, exist_action, doit)
    cu.execute("end transaction")
    cu.close()
    db.close()
#end cmd_save_more

def cmd_setcomment(args, opts) :
    dbname, snapid, comment = args
    snapid = int(snapid)
    db = open_db(dbname, DB_OPEN.READWRITE)
    db.cursor().execute \
      (
            "update snapshots set comment = %(comment)s where id = %(snapid)d"
        %
            {
                "snapid" : snapid,
                "comment" : sqlite.format_sql_value(comment)
            }
      )
    snap_existed = db_func(db, "changes") != 0
    db.close()
    if not snap_existed :
        raise ValueError("no such snapshot with ID %d" % snapid)
    #end if
#end cmd_setcomment

def cmd_editcomment(args, opts) :
    dbname, snapid = args
    snapid = int(snapid)
    db = open_db(dbname, DB_OPEN.READWRITE)
    editing = EditText(opts, "comment")
    comment = next \
      (
        db_iter
          (
            db,
            "select comment from snapshots where id = %d" % snapid,
            mapfn = single_field
          ),
        None
      )
    if comment == None :
        raise ValueError("no such snapshot with ID %d" % snapid)
    #end if
    status, comment = editing.edit(comment)
    if status != 0 :
        sys.stdout.write \
          (
            "editor %s terminated with status %d -- edit aborted\n" % (editing.editor, status)
          )
    else :
        db.cursor().execute \
          (
                "update snapshots set comment = %(comment)s where id = %(snapid)d"
            %
                {
                    "snapid" : snapid,
                    "comment" : sqlite.format_sql_value(comment)
                }
          )
    #end if
    db.close()
    editing.cleanup()
#end cmd_editcomment

def cmd_unsave(args, opts) :
    dbname, snapid = args[0:2]
    snapid = int(snapid)
    filespecs = args[2:]
    rules = list((True, parse_wildcard("", f)) for f in filespecs)
    doit = "dry-run" not in opts
    db = open_db(dbname, DB_OPEN.READWRITE)
    cu = db.cursor()
    cu.execute("begin transaction")
    to_delete = list \
      (
        f for f in
        db_iter
          (
            db,
            "select path from files where snapshot_id = %d" % snapid,
            mapfn = single_field
          )
        if filter_says_include(f, rules)
      )
    blobs_deleted = 0
    if len(to_delete) != 0 :
        sys.stdout.write \
          (
                "%sdelete files[%d]: %s\n"
            %
                (("would ", "")[doit], len(to_delete), ", ".join(repr(f) for f in to_delete))
          )
        if doit :
            cu.execute \
              (
                    "delete from files where snapshot_id = %d and path in (%s)"
                %
                    (
                        snapid,
                        ", ".join(sqlite.format_sql_value(f) for f in to_delete)
                    )
              )
        #end if
    else :
        sys.stdout.write("delete files: none.\n")
    #end if
    cu.execute("end transaction")
    cu.close()
    if doit :
        gc_blobs(db)
    #end if
    db.close()
#end cmd_unsave

def cmd_rename(args, opts) :
    dbname, snapid, oldname, newname = args
    snapid = int(snapid)
    db = open_db(dbname, DB_OPEN.READWRITE)
    if oldname.startswith("/") or newname.startswith("/") or oldname.endswith("/") :
        raise getopt.GetoptError("bad pathnames: %s, %s\n" % (repr(oldname), repr(newname)))
    #end if
    oldname = os.path.normpath("/" + oldname)[1:]
    isdir = newname.endswith("/")
    newname = os.path.normpath("/" + newname)[1:]
    if len(newname) != 0 and isdir :
        newname += "/"
    #end if
    if newname.endswith("/") :
        newname = \
            (
                newname
            +
                (lambda : oldname, lambda : oldname.rsplit("/", 1)[1])["/" in oldname]()
            )
    elif len(newname) == 0 :
        newname = oldname.rsplit("/", 1)[1]
    #end if
    db.cursor().execute \
      (
            "update files set path = %(newname)s where snapshot_id = %(snapid)d and path = %(oldname)s"
        %
            {
                "snapid" : snapid,
                "oldname" : sqlite.format_sql_value(oldname),
                "newname" : sqlite.format_sql_value(newname),
            }
      )
    renamed = db_func(db, "changes")
    db.close()
    sys.stderr.write("files affected: %d\n" % renamed) # debug
#end cmd_rename

def cmd_restore(args, opts) :
    dbname, snapid, destdir = args
    snapid = int(snapid)
    preserve_timestamps = "preserve-timestamps" in opts
    exist_action = parse_exist_action(opts.get("existing"), True)
    doit = "dry-run" not in opts
    db = open_db(dbname, DB_OPEN.READONLY)
    if not stat.S_ISDIR(os.lstat(destdir).st_mode) :
        raise ValueError("not a directory: “%s”" % basedir)
    #end if
    if next(db_iter(db, "select id from snapshots where id = %d" % snapid), None) == None :
        raise ValueError("no such snapshot with ID %d" % snapid)
    #end if
    if exist_action == EXIST_ACTION.REPLACE_ALL :
        temp_destdir = destdir + "-new"
        os.mkdir(temp_destdir)
        use_destdir = temp_destdir
    else :
        use_destdir = destdir
    #end if
    nr_restored = 0
    for childname, timestamp, contents in db_iter \
      (
        db,
            "select files.path, files.timestamp, file_blobs.contents from snapshots"
            " inner join files on snapshots.id = files.snapshot_id left join"
            " file_blobs on files.sha256hash = file_blobs.sha256hash where snapshots.id = %d"
        %
            snapid
      ) \
    :
        assert contents != None
        sys.stdout.write("%srestore %s\n" % (("would ", "")[doit], childname))
        childpath = os.path.join(use_destdir, childname)
        already_exists = os.path.exists(childpath)
        if already_exists and exist_action not in (EXIST_ACTION.REPLACE, EXIST_ACTION.REPLACE_ALL) :
            if exist_action != EXIST_ACTION.SKIP :
                raise FileExistsError \
                  (
                    "dest file “%s” already exists in %s" % (childname, destdir)
                  )
            #end if
        else :
            if doit :
                if already_exists :
                    os.unlink(childpath)
                #end if
                os.makedirs(os.path.split(childpath)[0], exist_ok = True)
                childfile = open(childpath, "wb")
                childfile.write(contents)
                childfile.close()
                if preserve_timestamps :
                    os.utime(childpath, (timestamp, timestamp))
                #end if
            #end if
        #end if
        nr_restored += 1
    #end for
    db.close()
    if exist_action == EXIST_ACTION.REPLACE_ALL :
        shutil.rmtree(destdir)
        os.rename(temp_destdir, destdir)
    #end if
    sys.stdout.write("%d files %srestored.\n" % (nr_restored, ("would have been ", "")[doit]))
#end cmd_restore

def cmd_delete(args, opts) :
    dbname, snapid = args
    snapid = int(snapid)
    verbose = "verbose" in opts
    db = open_db(dbname, DB_OPEN.READWRITE)
    if next(db_iter(db, "select id from snapshots where id = %d" % snapid), None) != None :
        cu = db.cursor()
        cu.execute("begin transaction")
        for field, table in \
            (
                ("snapshot_id", "files"),
                ("id", "snapshots"),
            ) \
        :
            cu.execute \
              (
                    "delete from %(table)s where %(field)s = %(snapid)d"
                %
                    {
                        "field" : field,
                        "table" : table,
                        "snapid" : snapid,
                    }
              )
        #end for
        cu.execute("end transaction")
        blobs_deleted = gc_blobs(db, cu)
        cu.close()
        if verbose :
            sys.stdout.write \
              (
                    "Snapshot with ID %d deleted from %s (%d file blobs deleted)\n"
                %
                    (snapid, dbname, blobs_deleted)
              )
        #end if
    else :
        if verbose :
            sys.stdout.write("No snapshot with ID %d in %s\n" % (snapid, dbname))
        #end if
    #end if
    db.close()
#end cmd_delete

def cmd_copy(args, opts) :
    db1name, snapids, db2name = args
    snapids = list(int(s) for s in snapids.split(","))
    db1 = open_db(db1name, DB_OPEN.READONLY)
    db2 = open_db(db2name, DB_OPEN.READWRITE)
    verbose = "verbose" in opts
    nr_snaps = 0
    for srcsnapid in snapids :
        srcsnap = list(db_iter
            (db1, "select comment, timestamp from snapshots where id = %d" % srcsnapid))
        if len(srcsnap) != 1 :
            raise getopt.GetoptError("no snapshot with ID %d in %s" % (srcsnapid, db1name))
        #end if
        message, snaptime = srcsnap[0]
        cu2 = db2.cursor()
        cu2.execute("begin transaction")
        cu2.execute \
          (
                "insert into snapshots(comment, timestamp) values(%s, %s)"
            %
                (sqlite.format_sql_value(message), str(snaptime))
          )
        dstsnapid = db_func(db2, "last_insert_rowid")
        if verbose :
            sys.stdout.write("* copy %s[%d] => %s[%d]\n" % (db1name, srcsnapid, db2name, dstsnapid))
        #end if
        nr_files = 0
        for childname, timestamp, contents, contents_hash in db_iter \
          (
            db1,
                "select files.path, files.timestamp, file_blobs.contents, files.sha256hash"
                " from snapshots inner join files on snapshots.id = files.snapshot_id"
                " left join file_blobs on files.sha256hash = file_blobs.sha256hash"
                " where snapshots.id = %d"
            %
                srcsnapid
          ) \
        :
            if verbose :
                sys.stdout.write("  copy %s (%d bytes)\n" % (childname, len(contents)))
            #end if
            assert contents != None
            cu2.execute \
              (
                    "insert or ignore into file_blobs(contents, sha256hash) values(%s, %s)"
                %
                    (
                        sqlite.format_sql_value(contents),
                        sqlite.format_sql_value(contents_hash),
                    )
              )
            cu2.execute \
              (
                    "insert into files(snapshot_id, path, timestamp, sha256hash)"
                    " values(%d, %s, %s, %s)"
                %
                    (
                        dstsnapid,
                        sqlite.format_sql_value(childname),
                        str(timestamp),
                        sqlite.format_sql_value(contents_hash),
                    )
              )
            nr_files += 1
        #end for
        cu2.execute("end transaction")
        if verbose :
            sys.stdout.write("  files copied: %d\n" % nr_files)
        #end if
        nr_snaps += 1
    #end for
    if verbose :
        sys.stdout.write("Snapshots copied: %d\n" % nr_snaps)
    #end if
    db1.close()
    db2.close()
#end cmd_copy

recognized_commands = \
    {
# key is command name, value is dictionary with following fields:
#     args -- nr required positional args, or tuple of min and max nr required positional args
#     opts -- tuple of long option names. If a name ends in an equal sign, then it takes a value.
#     multivalued -- optional tuple of option keywords which can occur multiple times
#     required -- optional tuple of option keywords which must be present
#     help_usage -- used to construct a usage string when giving help for the command.
#     help_descr -- explanatory text shown when giving help for the command.
#     action -- the function to invoke to actually perform the command.

        "help" :
            {
                "args" : (0, 1),
                "opts" : (),
                "action" : cmd_help,
                "help_usage" : "[cmd]",
                "help_descr" : "gives help about the specified command",
            },

        "init" :
            {
                "args" : 1,
                "opts" : ("nofilters",),
                "action" : cmd_init,
                "help_usage" : "[--nofilters] «dbname»",
                "help_descr" : "initializes a snapshot database with the specified name",
            },

        "setfilters" :
            {
                "args" : 2,
                "opts" : (),
                "action" : cmd_setfilters,
                "help_usage" : "«dbname» «filters_file»",
                "help_descr" :
                    "parses «filters_file» and sets the filters for snapshot database «dbname»",
            },

        "showfilters" :
            {
                "args" : 1,
                "opts" : (),
                "action" : cmd_showfilters,
                "help_usage" : "«dbname»",
                "help_descr" : "shows the current snapshot filters for «dbname»",
            },

        "editfilters" :
            {
                "args" : 1,
                "opts" : ("editor=",),
                "action" : cmd_editfilters,
                "help_usage" : "[--editor=«editor»] «dbname»",
                "help_descr" :
                    "lets you interactively edit the filters for the snapshot database «dbname»",
            },

        "list" :
            {
                "args" : 1,
                "opts" : ("long/l",),
                "action" : cmd_list,
                "help_usage" : "[--long|-l] «dbname»",
                "help_descr" : "lists currently-saved snapshots in «dbname»",
            },

        "save" :
            {
                "args" : (2, math.inf),
                "opts" : ("dry-run", "message/m=",),
                "action" : cmd_save,
                "help_usage" : "[--message=«message»] «dbname» «base_dir» [«file»...]",
                "help_descr" :
                    "saves a snapshot of files from «base_dir» into «dbname»"
                    " according to its currently loaded filter rules or the specified filespecs",
            },

        "save-more" :
            {
                "args" : (4, math.inf),
                "opts" : ("dry-run", "existing="),
                "action" : cmd_save_more,
                "help_usage" : "[--existing=skip|replace] «dbname» «snapid» «base_dir»"
                    " «file» [«file»...]",
                "help_descr" : "adds more files matching the given filespecs to a snapshot",
            },

        "setcomment" :
            {
                "args" : 3,
                "opts" : (),
                "action" : cmd_setcomment,
                "help_usage" : "«dbname» «snapid» «comment»",
                "help_descr" : "changes the comment associated with a snapshot",
            },

        "editcomment" :
            {
                "args" : 2,
                "opts" : ("editor=",),
                "action" : cmd_editcomment,
                "help_usage" : "[--editor=«editor»] «dbname» «snapid»",
                "help_descr" :
                    "lets you interactively edit the comment associated with a snapshot",
            },

        "unsave" :
            {
                "args" : (3, math.inf),
                "opts" : ("dry-run",),
                "action" : cmd_unsave,
                "help_usage" : "«dbname» «snapid» «filespec» [«filespec»...]",
                "help_descr" : "removes saved files matching the given filespecs from a snapshot",
            },

        "rename" :
            {
                "args" : 4,
                "opts" : (),
                "action" : cmd_rename,
                "help_usage" : "«dbname» «snapid» «oldfilespec» «newfilespec»",
                "help_descr" : "renames a saved file in a snapshot",
            },

        "restore" :
            {
                "args" : 3,
                "opts" : ("dry-run", "existing=", "preserve-timestamps/p",),
                "action" : cmd_restore,
                "help_usage" :
                    "[--existing=skip|replace|replace-all] [--preserve-timestamps|-p]"
                        " «dbname» «snapid» «dest_dir»",
                "help_descr" : "restores a previously-saved snapshot into a specified directory",
            },

        "delete" :
            {
                "args" : 2,
                "opts" : ("verbose/v",),
                "action" : cmd_delete,
                "help_usage" : "[--verbose|-v] «dbname» «snapshot_id»",
                "help_descr" : "deletes the snapshot with the specified ID from «dbname»",
            },

        "copy" :
            {
                "args" : 3,
                "opts" : ("verbose/v",),
                "action" : cmd_copy,
                "help_usage" : "«db1name» «snapid»[,«snapid»...] «db2name»",
                "help_descr" : "copies the specified snapshots from one database to another",
            },

    } # recognized_commands

#+
# Mainline
#-

def mainline() :
    if len(sys.argv) < 2 :
        raise getopt.GetoptError("need at least one arg, the cmd to execute")
    #end if
    cmd = sys.argv[1]
    cmd_entry = recognized_commands.get(cmd)
    if cmd_entry == None :
        raise getopt.GetoptError("unrecognized command %s" % repr(cmd))
    #end if
    short_opts = {}
    long_opts = []
    for opt in cmd_entry["opts"] :
        if "/" in opt :
            has_value = opt.endswith("=")
            long_opt, short_opt = opt[:len(opt) - has_value].split("/", 1)
            if len(short_opt) != 1 :
                raise RuntimeError("invalid short opt for %s" % repr(opt))
            #end if
            short_opts[short_opt] = {"long_opt" : long_opt, "has_value" : has_value}
            long_opts.append(long_opt + ("", "=")[has_value])
        else :
            long_opts.append(opt)
        #end if
    #end for
    opts_list, args = getopt.gnu_getopt \
      (
        sys.argv[2:],
        "".join(k + ("", ":")[short_opts[k]["has_value"]] for k in short_opts),
        long_opts
      )
    if type(cmd_entry["args"]) == tuple :
        if \
          (
                len(args) < cmd_entry["args"][0]
            or
                len(args) > cmd_entry["args"][1]
          ):
            raise getopt.GetoptError \
              (
                    "%s command needs %s args"
                %
                    (
                        cmd,
                        (
                            lambda : "%u..%u" % cmd_entry["args"],
                            lambda : "≥%u" % cmd_entry["args"][0],
                        )[math.isinf(cmd_entry["args"][1])](),
                    )
              )
        #end if
    else :
        if len(args) != cmd_entry["args"] :
            raise getopt.GetoptError \
              (
                "%s command needs exactly %u args" % (cmd, cmd_entry["args"])
              )
        #end if
    #end if
    opts = {}
    multi_opts = frozenset(cmd_entry.get("multivalued", ()))
    for keyword, value in opts_list :
        if keyword[:2] == "--" :
            opt = keyword[2:]
        elif keyword[:1] == "-" :
            opt = short_opts[keyword[1:]]["long_opt"]
        else :
            raise RuntimeError("unrecognized keyword %s" % repr(keyword))
        #end if
        if opt in multi_opts :
            values = opts.get(opt, [])
            values.append(value)
            opts[opt] = values
        else :
            opts[opt] = value
        #end if
    #end for
    required_opts = cmd_entry.get("required")
    if required_opts != None :
        missing = set(required_opts) - set(opts.keys())
        if len(missing) != 0 :
            raise getopt.GetoptError \
              (
                "%s command needs option(s) %s" % (cmd, ",".join(tuple(missing)))
              )
        #end if
    #end if
    cmd_entry["action"](args, opts) # can raise exceptions
#end mainline

mainline()
